{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13f9da3a",
   "metadata": {},
   "source": [
    "![Image](./UNIMAS_logo.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaf2ff86",
   "metadata": {},
   "source": [
    "# AKN32 Model Development\n",
    "## By: Awang Khairul Nizzam Awang Azzahari\n",
    "### Matrix number: 72136"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e083dd54",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "038b82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "# Essential for python to interact with the operating system\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Model development framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "# Image processing functions\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Subset, random_split\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tkinter import Image\n",
    "from PIL import Image\n",
    "\n",
    "# Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30086ea2",
   "metadata": {},
   "source": [
    "#### VGG16 Model Definition\n",
    "##### Initial Point for adjustments in the AKN32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b4f4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c36e3c66",
   "metadata": {},
   "source": [
    "#### AKN32 Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e515f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AKN32(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AKN32, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f971670",
   "metadata": {},
   "source": [
    "#### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "331381fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AKN32(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model = VGG16(num_classes=1000)\n",
    "akn_model = AKN32(num_classes=4)\n",
    "\n",
    "# Set the model to evaluation mode before inferencing it\n",
    "\n",
    "vgg_model.eval()\n",
    "akn_model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9939aa92",
   "metadata": {},
   "source": [
    "#### Training Dataset Batch Transform Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12fb0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training image applied transforms\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02a9eac0",
   "metadata": {},
   "source": [
    "#### Dataset Folder Datapath Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7d5212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92359</th>\n",
       "      <td>ffa47f6a7bf4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92360</th>\n",
       "      <td>ffc04fed30e6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92361</th>\n",
       "      <td>ffcf7b45f213</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92362</th>\n",
       "      <td>ffd97f8cd5aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92363</th>\n",
       "      <td>ffec9a18a3ce</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92364 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  level\n",
       "0           10_left      0\n",
       "1          10_right      0\n",
       "2           13_left      0\n",
       "3          13_right      0\n",
       "4           15_left      1\n",
       "...             ...    ...\n",
       "92359  ffa47f6a7bf4      2\n",
       "92360  ffc04fed30e6      0\n",
       "92361  ffcf7b45f213      2\n",
       "92362  ffd97f8cd5aa      0\n",
       "92363  ffec9a18a3ce      2\n",
       "\n",
       "[92364 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'C:\\\\Pytorch_for_fyp\\\\envfyp\\\\Data\\\\resized_traintest15_train19'\n",
    "train_df = pd.read_csv('C:\\\\Pytorch_for_fyp\\\\envfyp\\\\Data\\\\labels\\\\traintestLabels15_trainLabels19.csv')\n",
    "train_df #check the labels in data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2b777dd",
   "metadata": {},
   "source": [
    "#### Custom Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa1bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiaretDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_df, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image file name from the labels dataframe\n",
    "        image_name = self.labels_df.iloc[idx]['filename']\n",
    "        image_name += \".jpg\"  # Append the file extension \".jpg\" to the image_name\n",
    "        image_path = os.path.join(self.data_dir, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Open and convert to RGB format\n",
    "\n",
    "        # Apply the desired transformations if needed\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels_df.iloc[idx]['level']  # Get the label for the corresponding image\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49658848",
   "metadata": {},
   "source": [
    "#### Dataset Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c42e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = DiaretDataset('C:\\\\Pytorch_for_fyp\\\\envfyp\\\\Data\\\\resized_traintest15_train19',\n",
    "                              'C:\\\\Pytorch_for_fyp\\\\envfyp\\\\Data\\\\labels\\\\traintestLabels15_trainLabels19.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b20aaa8",
   "metadata": {},
   "source": [
    "#### Dataloading Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1580b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DiaretDataset(train_path, train_df, transformer)\n",
    "val_dataset = DiaretDataset(train_path, train_df, transformer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cc00be7",
   "metadata": {},
   "source": [
    "#### Image Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4017664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1, 3, 224, 224])\n",
      "Labels batch shape: torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze().permute(1, 2, 0)  # Permute dimensions for displaying with matplotlib\n",
    "label = train_labels[0]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# image conversion for testing purposes\n",
    "img_preproc = train_features[0].unsqueeze(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49854545",
   "metadata": {},
   "source": [
    "#### Dataset classes and tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9dd5028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    67148\n",
       "2    14152\n",
       "1     6575\n",
       "3     2280\n",
       "4     2209\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGgCAYAAABIanZ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2pUlEQVR4nO3dfXhU9Z3//1cSckPACTc2CbkIkC0WiAKBUMJob0BDRkx7SaUuWhZTRFy4Epcw10JNv5Tbtlha7izR2CrErnIJtCutQANjKFBluAtkCyisbWmx1UncCkSDTIbk/P7YX84yBEImZgjz8fm4rrku55z3+cznfU6OvjwzZybKsixLAAAAhonu7AkAAACEAyEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABgppJAzYMAARUVFtXgUFhZKki5evKjCwkL17t1b3bt316RJk1RTUxM0xpkzZ5Sfn6/ExEQlJydr7ty5unTpUlDN7t27NXLkSMXHx2vgwIEqLy9vMZfS0lINGDBACQkJysnJ0cGDB0NsHQAAmKxLKMWHDh1SY2Oj/fz48eMaP368HnzwQUnSnDlztG3bNm3evFlJSUkqKirSAw88oDfffFOS1NjYqPz8fKWmpmrfvn16//339cgjjyg2NlY//OEPJUmnT59Wfn6+Zs6cqZdfflmVlZV67LHH1KdPH7lcLknSxo0b5Xa7VVZWppycHK1evVoul0unTp1ScnJym/tpamrSe++9p1tuuUVRUVGh7AoAANBJLMvSRx99pLS0NEVHt3K9xvoUZs+ebX3+85+3mpqarHPnzlmxsbHW5s2b7fVvv/22Jcnyer2WZVnW9u3brejoaMvn89k1zz77rOVwOCy/329ZlmXNmzfPuv3224NeZ/LkyZbL5bKfjx492iosLLSfNzY2WmlpadayZctCmv+7775rSeLBgwcPHjx4RODj3XffbfW/8yFdyblcQ0ODXnrpJbndbkVFRamqqkqBQEC5ubl2zeDBg9WvXz95vV6NGTNGXq9XQ4cOVUpKil3jcrk0a9YsnThxQiNGjJDX6w0ao7mmuLjYft2qqiqVlJTY66Ojo5Wbmyuv19vqnP1+v/x+v/3c+v9/gP306dO65ZZb2rsrWggEAvrd736ncePGKTY2tsPGvZmY3iP9RT7Te6S/yGd6j+Hs76OPPlJGRsZ1/9vd7pCzZcsWnTt3Tt/+9rclST6fT3FxcerRo0dQXUpKinw+n11zecBpXt+8rrWauro6ffLJJzp79qwaGxuvWnPy5MlW57xs2TItXry4xXKv16vExMTWGw5RYmKiDhw40KFj3mxM75H+Ip/pPdJf5DO9x3D1d+HCBUm67kdN2h1yXnjhBU2YMEFpaWntHeKGKykpkdvttp/X1dUpPT1deXl5cjgcHfY6gUBAHo9H48ePNzKdS+b3SH+Rz/Qe6S/ymd5jOPurq6trU127Qs5f//pXvf766/rP//xPe1lqaqoaGhp07ty5oKs5NTU1Sk1NtWuuvAuq+e6ry2uuvCOrpqZGDodDXbt2VUxMjGJiYq5a0zzGtcTHxys+Pr7F8tjY2LD8gYVr3JuJ6T3SX+QzvUf6i3ym9xiO/to6Xru+J2f9+vVKTk5Wfn6+vSw7O1uxsbGqrKy0l506dUpnzpyR0+mUJDmdTh07dky1tbV2jcfjkcPhUGZmpl1z+RjNNc1jxMXFKTs7O6imqalJlZWVdg0AAEDIV3Kampq0fv16FRQUqEuX/9s8KSlJ06dPl9vtVq9eveRwOPTEE0/I6XRqzJgxkqS8vDxlZmZq6tSpWr58uXw+n+bPn6/CwkL7CsvMmTO1du1azZs3T48++qh27dqlTZs2adu2bfZrud1uFRQUaNSoURo9erRWr16t+vp6TZs27dPuDwAAYIiQQ87rr7+uM2fO6NFHH22xbtWqVYqOjtakSZPk9/vlcrn0zDPP2OtjYmK0detWzZo1S06nU926dVNBQYGWLFli12RkZGjbtm2aM2eO1qxZo759++r555+3vyNHkiZPnqwPPvhACxYskM/nU1ZWlioqKlp8GBkAAHx2hRxy8vLy7Fuvr5SQkKDS0lKVlpZec/v+/ftr+/btrb7G2LFjdfTo0VZrioqKVFRUdP0JAwCAzyR+uwoAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMFK7f4Uc13fHoh3yN7b+M/A3k788lX/9IgAAIgRXcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI4Uccv7+97/rX/7lX9S7d2917dpVQ4cO1eHDh+31lmVpwYIF6tOnj7p27arc3Fy98847QWN8+OGHmjJlihwOh3r06KHp06fr448/Dqr5wx/+oC9/+ctKSEhQenq6li9f3mIumzdv1uDBg5WQkKChQ4dq+/btobYDAAAMFVLIOXv2rO666y7Fxsbqt7/9rd566y2tWLFCPXv2tGuWL1+up59+WmVlZTpw4IC6desml8ulixcv2jVTpkzRiRMn5PF4tHXrVu3du1ePP/64vb6urk55eXnq37+/qqqq9OMf/1iLFi3Sz372M7tm3759evjhhzV9+nQdPXpUEydO1MSJE3X8+PFPsz8AAIAhuoRS/KMf/Ujp6elav369vSwjI8P+Z8uytHr1as2fP1/333+/JOkXv/iFUlJStGXLFj300EN6++23VVFRoUOHDmnUqFGSpJ/+9Ke677779JOf/ERpaWl6+eWX1dDQoHXr1ikuLk633367qqurtXLlSjsMrVmzRvfee6/mzp0rSVq6dKk8Ho/Wrl2rsrKyT7dXAABAxAvpSs5vfvMbjRo1Sg8++KCSk5M1YsQI/fznP7fXnz59Wj6fT7m5ufaypKQk5eTkyOv1SpK8Xq969OhhBxxJys3NVXR0tA4cOGDXfOUrX1FcXJxd43K5dOrUKZ09e9auufx1mmuaXwcAAHy2hXQl589//rOeffZZud1uffe739WhQ4f0b//2b4qLi1NBQYF8Pp8kKSUlJWi7lJQUe53P51NycnLwJLp0Ua9evYJqLr9CdPmYPp9PPXv2lM/na/V1rsbv98vv99vP6+rqJEmBQECBQKDN++F6mseKj7Y6bMwbIZR90FzbkfvtZkJ/kc/0Hukv8pneYzj7a+uYIYWcpqYmjRo1Sj/84Q8lSSNGjNDx48dVVlamgoKC0Gd5gy1btkyLFy9usXznzp1KTEzs8NdbOqqpw8cMp/Z8cNvj8YRhJjcP+ot8pvdIf5HP9B7D0d+FCxfaVBdSyOnTp48yMzODlg0ZMkS/+tWvJEmpqamSpJqaGvXp08euqampUVZWll1TW1sbNMalS5f04Ycf2tunpqaqpqYmqKb5+fVqmtdfTUlJidxut/28rq5O6enpysvLk8PhaL35EAQCAXk8Hn3vcLT8TVEdNm64HV/kanNtc4/jx49XbGxsGGfVOegv8pneI/1FPtN7DGd/ze/EXE9IIeeuu+7SqVOngpb993//t/r37y/pfz+EnJqaqsrKSjvU1NXV6cCBA5o1a5Ykyel06ty5c6qqqlJ2drYkadeuXWpqalJOTo5d8//+3/9TIBCwd4zH49GgQYPsO7mcTqcqKytVXFxsz8Xj8cjpdF5z/vHx8YqPj2+xPDY2Nix/YP6mKPkbIyfktGcfhGvf3SzoL/KZ3iP9RT7TewxHf20dL6QPHs+ZM0f79+/XD3/4Q/3xj3/Uhg0b9LOf/UyFhYWSpKioKBUXF+v73/++fvOb3+jYsWN65JFHlJaWpokTJ0r63ys/9957r2bMmKGDBw/qzTffVFFRkR566CGlpaVJkr71rW8pLi5O06dP14kTJ7Rx40atWbMm6CrM7NmzVVFRoRUrVujkyZNatGiRDh8+rKKiolBaAgAAhgrpSs4Xv/hFvfrqqyopKdGSJUuUkZGh1atXa8qUKXbNvHnzVF9fr8cff1znzp3Tl770JVVUVCghIcGuefnll1VUVKR77rlH0dHRmjRpkp5++ml7fVJSknbu3KnCwkJlZ2fr1ltv1YIFC4K+S+fOO+/Uhg0bNH/+fH33u9/Vbbfdpi1btuiOO+74NPsDAAAYIqSQI0lf+9rX9LWvfe2a66OiorRkyRItWbLkmjW9evXShg0bWn2dYcOG6fe//32rNQ8++KAefPDB1icMAAA+k/jtKgAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADBSSCFn0aJFioqKCnoMHjzYXn/x4kUVFhaqd+/e6t69uyZNmqSampqgMc6cOaP8/HwlJiYqOTlZc+fO1aVLl4Jqdu/erZEjRyo+Pl4DBw5UeXl5i7mUlpZqwIABSkhIUE5Ojg4ePBhKKwAAwHAhX8m5/fbb9f7779uPN954w143Z84cvfbaa9q8ebP27Nmj9957Tw888IC9vrGxUfn5+WpoaNC+ffv04osvqry8XAsWLLBrTp8+rfz8fI0bN07V1dUqLi7WY489ph07dtg1GzdulNvt1sKFC3XkyBENHz5cLpdLtbW17d0PAADAMCGHnC5duig1NdV+3HrrrZKk8+fP64UXXtDKlSt19913Kzs7W+vXr9e+ffu0f/9+SdLOnTv11ltv6aWXXlJWVpYmTJigpUuXqrS0VA0NDZKksrIyZWRkaMWKFRoyZIiKior0zW9+U6tWrbLnsHLlSs2YMUPTpk1TZmamysrKlJiYqHXr1nXEPgEAAAboEuoG77zzjtLS0pSQkCCn06lly5apX79+qqqqUiAQUG5url07ePBg9evXT16vV2PGjJHX69XQoUOVkpJi17hcLs2aNUsnTpzQiBEj5PV6g8ZorikuLpYkNTQ0qKqqSiUlJfb66Oho5ebmyuv1tjp3v98vv99vP6+rq5MkBQIBBQKBUHfFNTWPFR9tddiYN0Io+6C5tiP3282E/iKf6T3SX+Qzvcdw9tfWMUMKOTk5OSovL9egQYP0/vvva/Hixfryl7+s48ePy+fzKS4uTj169AjaJiUlRT6fT5Lk8/mCAk7z+uZ1rdXU1dXpk08+0dmzZ9XY2HjVmpMnT7Y6/2XLlmnx4sUtlu/cuVOJiYnX3wEhWjqqqcPHDKft27eHvI3H4wnDTG4e9Bf5TO+R/iKf6T2Go78LFy60qS6kkDNhwgT7n4cNG6acnBz1799fmzZtUteuXUObYScoKSmR2+22n9fV1Sk9PV15eXlyOBwd9jqBQEAej0ffOxwtf1NUh40bbscXudpc29zj+PHjFRsbG8ZZdQ76i3ym90h/kc/0HsPZX/M7MdcT8ttVl+vRo4e+8IUv6I9//KPGjx+vhoYGnTt3LuhqTk1NjVJTUyVJqampLe6Car776vKaK+/IqqmpkcPhUNeuXRUTE6OYmJir1jSPcS3x8fGKj49vsTw2NjYsf2D+pij5GyMn5LRnH4Rr390s6C/ymd4j/UU+03sMR39tHe9TfU/Oxx9/rD/96U/q06ePsrOzFRsbq8rKSnv9qVOndObMGTmdTkmS0+nUsWPHgu6C8ng8cjgcyszMtGsuH6O5pnmMuLg4ZWdnB9U0NTWpsrLSrgEAAAgp5Pz7v/+79uzZo7/85S/at2+fvvGNbygmJkYPP/ywkpKSNH36dLndbv3ud79TVVWVpk2bJqfTqTFjxkiS8vLylJmZqalTp+q//uu/tGPHDs2fP1+FhYX2FZaZM2fqz3/+s+bNm6eTJ0/qmWee0aZNmzRnzhx7Hm63Wz//+c/14osv6u2339asWbNUX1+vadOmdeCuAQAAkSykt6v+9re/6eGHH9Y//vEPfe5zn9OXvvQl7d+/X5/73OckSatWrVJ0dLQmTZokv98vl8ulZ555xt4+JiZGW7du1axZs+R0OtWtWzcVFBRoyZIldk1GRoa2bdumOXPmaM2aNerbt6+ef/55uVz/93mRyZMn64MPPtCCBQvk8/mUlZWlioqKFh9GBgAAn10hhZxXXnml1fUJCQkqLS1VaWnpNWv69+9/3bt4xo4dq6NHj7ZaU1RUpKKiolZrAADAZxe/XQUAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACM9KlCzlNPPaWoqCgVFxfbyy5evKjCwkL17t1b3bt316RJk1RTUxO03ZkzZ5Sfn6/ExEQlJydr7ty5unTpUlDN7t27NXLkSMXHx2vgwIEqLy9v8fqlpaUaMGCAEhISlJOTo4MHD36adgAAgEHaHXIOHTqk5557TsOGDQtaPmfOHL322mvavHmz9uzZo/fee08PPPCAvb6xsVH5+flqaGjQvn379OKLL6q8vFwLFiywa06fPq38/HyNGzdO1dXVKi4u1mOPPaYdO3bYNRs3bpTb7dbChQt15MgRDR8+XC6XS7W1te1tCQAAGKRdIefjjz/WlClT9POf/1w9e/a0l58/f14vvPCCVq5cqbvvvlvZ2dlav3699u3bp/3790uSdu7cqbfeeksvvfSSsrKyNGHCBC1dulSlpaVqaGiQJJWVlSkjI0MrVqzQkCFDVFRUpG9+85tatWqV/VorV67UjBkzNG3aNGVmZqqsrEyJiYlat27dp9kfAADAEO0KOYWFhcrPz1dubm7Q8qqqKgUCgaDlgwcPVr9+/eT1eiVJXq9XQ4cOVUpKil3jcrlUV1enEydO2DVXju1yuewxGhoaVFVVFVQTHR2t3NxcuwYAAHy2dQl1g1deeUVHjhzRoUOHWqzz+XyKi4tTjx49gpanpKTI5/PZNZcHnOb1zetaq6mrq9Mnn3yis2fPqrGx8ao1J0+evObc/X6//H6//byurk6SFAgEFAgEWms7JM1jxUdbHTbmjRDKPmiu7cj9djOhv8hneo/0F/lM7zGc/bV1zJBCzrvvvqvZs2fL4/EoISGhXRPrTMuWLdPixYtbLN+5c6cSExM7/PWWjmrq8DHDafv27SFv4/F4wjCTmwf9RT7Te6S/yGd6j+Ho78KFC22qCynkVFVVqba2ViNHjrSXNTY2au/evVq7dq127NihhoYGnTt3LuhqTk1NjVJTUyVJqampLe6Car776vKaK+/IqqmpkcPhUNeuXRUTE6OYmJir1jSPcTUlJSVyu93287q6OqWnpysvL08OhyOEPdG6QCAgj8ej7x2Olr8pqsPGDbfji1xtrm3ucfz48YqNjQ3jrDoH/UU+03ukv8hneo/h7K/5nZjrCSnk3HPPPTp27FjQsmnTpmnw4MH6zne+o/T0dMXGxqqyslKTJk2SJJ06dUpnzpyR0+mUJDmdTv3gBz9QbW2tkpOTJf1vynM4HMrMzLRrrryq4PF47DHi4uKUnZ2tyspKTZw4UZLU1NSkyspKFRUVXXP+8fHxio+Pb7E8NjY2LH9g/qYo+RsjJ+S0Zx+Ea9/dLOgv8pneI/1FPtN7DEd/bR0vpJBzyy236I477gha1q1bN/Xu3dtePn36dLndbvXq1UsOh0NPPPGEnE6nxowZI0nKy8tTZmampk6dquXLl8vn82n+/PkqLCy0A8jMmTO1du1azZs3T48++qh27dqlTZs2adu2bfbrut1uFRQUaNSoURo9erRWr16t+vp6TZs2LZSWAACAoUL+4PH1rFq1StHR0Zo0aZL8fr9cLpeeeeYZe31MTIy2bt2qWbNmyel0qlu3biooKNCSJUvsmoyMDG3btk1z5szRmjVr1LdvXz3//PNyuf7v7ZTJkyfrgw8+0IIFC+Tz+ZSVlaWKiooWH0YGAACfTZ865OzevTvoeUJCgkpLS1VaWnrNbfr373/dD7mOHTtWR48ebbWmqKio1benAADAZxe/XQUAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGCinkPPvssxo2bJgcDoccDoecTqd++9vf2usvXryowsJC9e7dW927d9ekSZNUU1MTNMaZM2eUn5+vxMREJScna+7cubp06VJQze7duzVy5EjFx8dr4MCBKi8vbzGX0tJSDRgwQAkJCcrJydHBgwdDaQUAABgupJDTt29fPfXUU6qqqtLhw4d199136/7779eJEyckSXPmzNFrr72mzZs3a8+ePXrvvff0wAMP2Ns3NjYqPz9fDQ0N2rdvn1588UWVl5drwYIFds3p06eVn5+vcePGqbq6WsXFxXrssce0Y8cOu2bjxo1yu91auHChjhw5ouHDh8vlcqm2tvbT7g8AAGCIkELO17/+dd1333267bbb9IUvfEE/+MEP1L17d+3fv1/nz5/XCy+8oJUrV+ruu+9Wdna21q9fr3379mn//v2SpJ07d+qtt97SSy+9pKysLE2YMEFLly5VaWmpGhoaJEllZWXKyMjQihUrNGTIEBUVFemb3/ymVq1aZc9j5cqVmjFjhqZNm6bMzEyVlZUpMTFR69at68BdAwAAIlmX9m7Y2NiozZs3q76+Xk6nU1VVVQoEAsrNzbVrBg8erH79+snr9WrMmDHyer0aOnSoUlJS7BqXy6VZs2bpxIkTGjFihLxeb9AYzTXFxcWSpIaGBlVVVamkpMReHx0drdzcXHm93lbn7Pf75ff77ed1dXWSpEAgoEAg0N5d0ULzWPHRVoeNeSOEsg+aaztyv91M6C/ymd4j/UU+03sMZ39tHTPkkHPs2DE5nU5dvHhR3bt316uvvqrMzExVV1crLi5OPXr0CKpPSUmRz+eTJPl8vqCA07y+eV1rNXV1dfrkk0909uxZNTY2XrXm5MmTrc592bJlWrx4cYvlO3fuVGJi4vWbD9HSUU0dPmY4bd++PeRtPB5PGGZy86C/yGd6j/QX+UzvMRz9XbhwoU11IYecQYMGqbq6WufPn9cvf/lLFRQUaM+ePSFPsDOUlJTI7Xbbz+vq6pSenq68vDw5HI4Oe51AICCPx6PvHY6Wvymqw8YNt+OLXG2ube5x/Pjxio2NDeOsOgf9RT7Te6S/yGd6j+Hsr/mdmOsJOeTExcVp4MCBkqTs7GwdOnRIa9as0eTJk9XQ0KBz584FXc2pqalRamqqJCk1NbXFXVDNd19dXnPlHVk1NTVyOBzq2rWrYmJiFBMTc9Wa5jGuJT4+XvHx8S2Wx8bGhuUPzN8UJX9j5ISc9uyDcO27mwX9RT7Te6S/yGd6j+Hor63jfervyWlqapLf71d2drZiY2NVWVlprzt16pTOnDkjp9MpSXI6nTp27FjQXVAej0cOh0OZmZl2zeVjNNc0jxEXF6fs7OygmqamJlVWVto1AAAAIV3JKSkp0YQJE9SvXz999NFH2rBhg3bv3q0dO3YoKSlJ06dPl9vtVq9eveRwOPTEE0/I6XRqzJgxkqS8vDxlZmZq6tSpWr58uXw+n+bPn6/CwkL7CsvMmTO1du1azZs3T48++qh27dqlTZs2adu2bfY83G63CgoKNGrUKI0ePVqrV69WfX29pk2b1oG7BgAARLKQQk5tba0eeeQRvf/++0pKStKwYcO0Y8cOjR8/XpK0atUqRUdHa9KkSfL7/XK5XHrmmWfs7WNiYrR161bNmjVLTqdT3bp1U0FBgZYsWWLXZGRkaNu2bZozZ47WrFmjvn376vnnn5fL9X+fF5k8ebI++OADLViwQD6fT1lZWaqoqGjxYWQAAPDZFVLIeeGFF1pdn5CQoNLSUpWWll6zpn///te9i2fs2LE6evRoqzVFRUUqKipqtQYAAHx28dtVAADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEghhZxly5bpi1/8om655RYlJydr4sSJOnXqVFDNxYsXVVhYqN69e6t79+6aNGmSampqgmrOnDmj/Px8JSYmKjk5WXPnztWlS5eCanbv3q2RI0cqPj5eAwcOVHl5eYv5lJaWasCAAUpISFBOTo4OHjwYSjsAAMBgIYWcPXv2qLCwUPv375fH41EgEFBeXp7q6+vtmjlz5ui1117T5s2btWfPHr333nt64IEH7PWNjY3Kz89XQ0OD9u3bpxdffFHl5eVasGCBXXP69Gnl5+dr3Lhxqq6uVnFxsR577DHt2LHDrtm4caPcbrcWLlyoI0eOaPjw4XK5XKqtrf00+wMAABiiSyjFFRUVQc/Ly8uVnJysqqoqfeUrX9H58+f1wgsvaMOGDbr77rslSevXr9eQIUO0f/9+jRkzRjt37tRbb72l119/XSkpKcrKytLSpUv1ne98R4sWLVJcXJzKysqUkZGhFStWSJKGDBmiN954Q6tWrZLL5ZIkrVy5UjNmzNC0adMkSWVlZdq2bZvWrVunJ5988lPvGAAAENlCCjlXOn/+vCSpV69ekqSqqioFAgHl5ubaNYMHD1a/fv3k9Xo1ZswYeb1eDR06VCkpKXaNy+XSrFmzdOLECY0YMUJerzdojOaa4uJiSVJDQ4OqqqpUUlJir4+OjlZubq68Xu815+v3++X3++3ndXV1kqRAIKBAINDOvdBS81jx0VaHjXkjhLIPmms7cr/dTOgv8pneI/1FPtN7DGd/bR2z3SGnqalJxcXFuuuuu3THHXdIknw+n+Li4tSjR4+g2pSUFPl8Prvm8oDTvL55XWs1dXV1+uSTT3T27Fk1NjZetebkyZPXnPOyZcu0ePHiFst37typxMTENnQdmqWjmjp8zHDavn17yNt4PJ4wzOTmQX+Rz/Qe6S/ymd5jOPq7cOFCm+raHXIKCwt1/PhxvfHGG+0d4oYrKSmR2+22n9fV1Sk9PV15eXlyOBwd9jqBQEAej0ffOxwtf1NUh40bbscXudpc29zj+PHjFRsbG8ZZdQ76i3ym90h/kc/0HsPZX/M7MdfTrpBTVFSkrVu3au/everbt6+9PDU1VQ0NDTp37lzQ1ZyamhqlpqbaNVfeBdV899XlNVfekVVTUyOHw6GuXbsqJiZGMTExV61pHuNq4uPjFR8f32J5bGxsWP7A/E1R8jdGTshpzz4I1767WdBf5DO9R/qLfKb3GI7+2jpeSHdXWZaloqIivfrqq9q1a5cyMjKC1mdnZys2NlaVlZX2slOnTunMmTNyOp2SJKfTqWPHjgXdBeXxeORwOJSZmWnXXD5Gc03zGHFxccrOzg6qaWpqUmVlpV0DAAA+20K6klNYWKgNGzbo17/+tW655Rb7MzRJSUnq2rWrkpKSNH36dLndbvXq1UsOh0NPPPGEnE6nxowZI0nKy8tTZmampk6dquXLl8vn82n+/PkqLCy0r7LMnDlTa9eu1bx58/Too49q165d2rRpk7Zt22bPxe12q6CgQKNGjdLo0aO1evVq1dfX23dbAQCAz7aQQs6zzz4rSRo7dmzQ8vXr1+vb3/62JGnVqlWKjo7WpEmT5Pf75XK59Mwzz9i1MTEx2rp1q2bNmiWn06lu3bqpoKBAS5YssWsyMjK0bds2zZkzR2vWrFHfvn31/PPP27ePS9LkyZP1wQcfaMGCBfL5fMrKylJFRUWLDyMDAIDPppBCjmVd/5bohIQElZaWqrS09Jo1/fv3v+6dPGPHjtXRo0dbrSkqKlJRUdF15wQAAD57+O0qAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASF06ewIAEE53LNohf2NUZ0+jzf7yVH5nTwEwBldyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJFCDjl79+7V17/+daWlpSkqKkpbtmwJWm9ZlhYsWKA+ffqoa9euys3N1TvvvBNU8+GHH2rKlClyOBzq0aOHpk+fro8//jio5g9/+IO+/OUvKyEhQenp6Vq+fHmLuWzevFmDBw9WQkKChg4dqu3bt4faDgAAMFTIIae+vl7Dhw9XaWnpVdcvX75cTz/9tMrKynTgwAF169ZNLpdLFy9etGumTJmiEydOyOPxaOvWrdq7d68ef/xxe31dXZ3y8vLUv39/VVVV6cc//rEWLVqkn/3sZ3bNvn379PDDD2v69Ok6evSoJk6cqIkTJ+r48eOhtgQAAAzUJdQNJkyYoAkTJlx1nWVZWr16tebPn6/7779fkvSLX/xCKSkp2rJlix566CG9/fbbqqio0KFDhzRq1ChJ0k9/+lPdd999+slPfqK0tDS9/PLLamho0Lp16xQXF6fbb79d1dXVWrlypR2G1qxZo3vvvVdz586VJC1dulQej0dr165VWVlZu3YGAAAwR8ghpzWnT5+Wz+dTbm6uvSwpKUk5OTnyer166KGH5PV61aNHDzvgSFJubq6io6N14MABfeMb35DX69VXvvIVxcXF2TUul0s/+tGPdPbsWfXs2VNer1dutzvo9V0uV4u3zy7n9/vl9/vt53V1dZKkQCCgQCDwadu3NY8VH2112Jg3Qij7oLm2I/fbzYT+Ip/p56Hpx9D0/iTzewxnf20ds0NDjs/nkySlpKQELU9JSbHX+Xw+JScnB0+iSxf16tUrqCYjI6PFGM3revbsKZ/P1+rrXM2yZcu0ePHiFst37typxMTEtrQYkqWjmjp8zHBqz2eaPB5PGGZy86C/yGf6eWj6MTS9P8n8HsPR34ULF9pU16Eh52ZXUlISdPWnrq5O6enpysvLk8Ph6LDXCQQC8ng8+t7haPmbojps3HA7vsjV5trmHsePH6/Y2Ngwzqpz0F/kM/08NP0Ymt6fZH6P4eyv+Z2Y6+nQkJOamipJqqmpUZ8+fezlNTU1ysrKsmtqa2uDtrt06ZI+/PBDe/vU1FTV1NQE1TQ/v15N8/qriY+PV3x8fIvlsbGxYfkD8zdFyd8YOf9ybc8+CNe+u1nQX+Qz/Tw0/Ria3p9kfo/h6K+t43Xo9+RkZGQoNTVVlZWV9rK6ujodOHBATqdTkuR0OnXu3DlVVVXZNbt27VJTU5NycnLsmr179wa95+bxeDRo0CD17NnTrrn8dZprml8HAAB8toUccj7++GNVV1erurpa0v9+2Li6ulpnzpxRVFSUiouL9f3vf1+/+c1vdOzYMT3yyCNKS0vTxIkTJUlDhgzRvffeqxkzZujgwYN68803VVRUpIceekhpaWmSpG9961uKi4vT9OnTdeLECW3cuFFr1qwJeqtp9uzZqqio0IoVK3Ty5EktWrRIhw8fVlFR0affKwAAIOKF/HbV4cOHNW7cOPt5c/AoKChQeXm55s2bp/r6ej3++OM6d+6cvvSlL6miokIJCQn2Ni+//LKKiop0zz33KDo6WpMmTdLTTz9tr09KStLOnTtVWFio7Oxs3XrrrVqwYEHQd+nceeed2rBhg+bPn6/vfve7uu2227Rlyxbdcccd7doRAADALCGHnLFjx8qyrn1LZlRUlJYsWaIlS5Zcs6ZXr17asGFDq68zbNgw/f73v2+15sEHH9SDDz7Y+oQBAMBnEr9dBQAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjhfzbVcDNZMCT28IybnyMpeWjpTsW7ZC/MapDx/7LU/kdOh4A4Oq4kgMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIXTp7AgCAyDbgyW0dPmZ8jKXlo6U7Fu2QvzGqw8f/y1P5HT4mbj6EHAAAIkA4wmQ4NQfVzsTbVQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARor4kFNaWqoBAwYoISFBOTk5OnjwYGdPCQAA3AQiOuRs3LhRbrdbCxcu1JEjRzR8+HC5XC7V1tZ29tQAAEAni+iQs3LlSs2YMUPTpk1TZmamysrKlJiYqHXr1nX21AAAQCeL2G88bmhoUFVVlUpKSuxl0dHRys3Nldfrveo2fr9ffr/ffn7+/HlJ0ocffqhAINBhcwsEArpw4YK6BKLV2NTxX0ceLv/4xz/aXNvc4z/+8Q/FxsaGcVat63KpPjzjNlm6cKEpLMcwlP0cLjfL8Qsn08/Dm+kYhuM8DOc5KEXmeRiuf9+FS/MxDMff6EcffSRJsiyr9UIrQv3973+3JFn79u0LWj537lxr9OjRV91m4cKFliQePHjw4MGDhwGPd999t9WsELFXctqjpKREbrfbft7U1KQPP/xQvXv3VlRUx/2fQl1dndLT0/Xuu+/K4XB02Lg3E9N7pL/IZ3qP9Bf5TO8xnP1ZlqWPPvpIaWlprdZFbMi59dZbFRMTo5qamqDlNTU1Sk1Nveo28fHxio+PD1rWo0ePcE1RDofDyD/cy5neI/1FPtN7pL/IZ3qP4eovKSnpujUR+8HjuLg4ZWdnq7Ky0l7W1NSkyspKOZ3OTpwZAAC4GUTslRxJcrvdKigo0KhRozR69GitXr1a9fX1mjZtWmdPDQAAdLKIDjmTJ0/WBx98oAULFsjn8ykrK0sVFRVKSUnp1HnFx8dr4cKFLd4aM4npPdJf5DO9R/qLfKb3eDP0F2VZ17v/CgAAIPJE7GdyAAAAWkPIAQAARiLkAAAAIxFyAACAkQg57VRaWqoBAwYoISFBOTk5OnjwYKv1mzdv1uDBg5WQkKChQ4dq+/btN2im7RNKf+Xl5YqKigp6JCQk3MDZhmbv3r36+te/rrS0NEVFRWnLli3X3Wb37t0aOXKk4uPjNXDgQJWXl4d9np9GqD3u3r27xTGMioqSz+e7MRMO0bJly/TFL35Rt9xyi5KTkzVx4kSdOnXquttFynnYnv4i6Tx89tlnNWzYMPtL4pxOp37729+2uk2kHLtmofYYScfvap566ilFRUWpuLi41bobfRwJOe2wceNGud1uLVy4UEeOHNHw4cPlcrlUW1t71fp9+/bp4Ycf1vTp03X06FFNnDhREydO1PHjx2/wzNsm1P6k//1Gy/fff99+/PWvf72BMw5NfX29hg8frtLS0jbVnz59Wvn5+Ro3bpyqq6tVXFysxx57TDt27AjzTNsv1B6bnTp1Kug4Jicnh2mGn86ePXtUWFio/fv3y+PxKBAIKC8vT/X11/4Bw0g6D9vTnxQ552Hfvn311FNPqaqqSocPH9bdd9+t+++/XydOnLhqfSQdu2ah9ihFzvG70qFDh/Tcc89p2LBhrdZ1ynHsmJ/L/GwZPXq0VVhYaD9vbGy00tLSrGXLll21/p//+Z+t/Pz8oGU5OTnWv/7rv4Z1nu0Van/r16+3kpKSbtDsOpYk69VXX221Zt68edbtt98etGzy5MmWy+UK48w6Tlt6/N3vfmdJss6ePXtD5tTRamtrLUnWnj17rlkTaefh5drSXySfh5ZlWT179rSef/75q66L5GN3udZ6jNTj99FHH1m33Xab5fF4rK9+9avW7Nmzr1nbGceRKzkhamhoUFVVlXJzc+1l0dHRys3Nldfrveo2Xq83qF6SXC7XNes7U3v6k6SPP/5Y/fv3V3p6+nX/byXSRNLx+7SysrLUp08fjR8/Xm+++WZnT6fNzp8/L0nq1avXNWsi+Ti2pT8pMs/DxsZGvfLKK6qvr7/mT/JE8rGT2tajFJnHr7CwUPn5+S2Oz9V0xnEk5ITof/7nf9TY2NjiW5VTUlKu+fkFn88XUn1nak9/gwYN0rp16/TrX/9aL730kpqamnTnnXfqb3/7242Ycthd6/jV1dXpk08+6aRZdaw+ffqorKxMv/rVr/SrX/1K6enpGjt2rI4cOdLZU7uupqYmFRcX66677tIdd9xxzbpIOg8v19b+Iu08PHbsmLp37674+HjNnDlTr776qjIzM69aG6nHLpQeI+34SdIrr7yiI0eOaNmyZW2q74zjGNE/64Cbg9PpDPq/kzvvvFNDhgzRc889p6VLl3bizNBWgwYN0qBBg+znd955p/70pz9p1apV+o//+I9OnNn1FRYW6vjx43rjjTc6eyph0db+Iu08HDRokKqrq3X+/Hn98pe/VEFBgfbs2XPNEBCJQukx0o7fu+++q9mzZ8vj8dzUH5Am5ITo1ltvVUxMjGpqaoKW19TUKDU19arbpKamhlTfmdrT35ViY2M1YsQI/fGPfwzHFG+4ax0/h8Ohrl27dtKswm/06NE3fXAoKirS1q1btXfvXvXt27fV2kg6D5uF0t+VbvbzMC4uTgMHDpQkZWdn69ChQ1qzZo2ee+65FrWReOyk0Hq80s1+/KqqqlRbW6uRI0fayxobG7V3716tXbtWfr9fMTExQdt0xnHk7aoQxcXFKTs7W5WVlfaypqYmVVZWXvO9VqfTGVQvSR6Pp9X3ZjtLe/q7UmNjo44dO6Y+ffqEa5o3VCQdv45UXV190x5Dy7JUVFSkV199Vbt27VJGRsZ1t4mk49ie/q4UaedhU1OT/H7/VddF0rFrTWs9XulmP3733HOPjh07purqavsxatQoTZkyRdXV1S0CjtRJxzFsH2k22CuvvGLFx8db5eXl1ltvvWU9/vjjVo8ePSyfz2dZlmVNnTrVevLJJ+36N9980+rSpYv1k5/8xHr77bethQsXWrGxsdaxY8c6q4VWhdrf4sWLrR07dlh/+tOfrKqqKuuhhx6yEhISrBMnTnRWC6366KOPrKNHj1pHjx61JFkrV660jh49av31r3+1LMuynnzySWvq1Kl2/Z///GcrMTHRmjt3rvX2229bpaWlVkxMjFVRUdFZLVxXqD2uWrXK2rJli/XOO+9Yx44ds2bPnm1FR0dbr7/+eme10KpZs2ZZSUlJ1u7du63333/ffly4cMGuieTzsD39RdJ5+OSTT1p79uyxTp8+bf3hD3+wnnzySSsqKsrauXOnZVmRfeyahdpjJB2/a7ny7qqb4TgSctrppz/9qdWvXz8rLi7OGj16tLV//3573Ve/+lWroKAgqH7Tpk3WF77wBSsuLs66/fbbrW3btt3gGYcmlP6Ki4vt2pSUFOu+++6zjhw50gmzbpvm26WvfDT3VFBQYH31q19tsU1WVpYVFxdn/dM//ZO1fv36Gz7vUITa449+9CPr85//vJWQkGD16tXLGjt2rLVr167OmXwbXK03SUHHJZLPw/b0F0nn4aOPPmr179/fiouLsz73uc9Z99xzj/0ff8uK7GPXLNQeI+n4XcuVIedmOI5RlmVZ4btOBAAA0Dn4TA4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARvr/ALfv6cxPKqIvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['level'].hist()\n",
    "train_df['level'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "079ba50d",
   "metadata": {},
   "source": [
    "#### Dataset Split for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "496764a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 58\n",
      "Validation dataset size: 15\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(8816001000)\n",
    "\n",
    "# Define the sizes for training and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# Split the dataset into training and validation subsets\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Print the sizes of the resulting subsets\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c99ca129",
   "metadata": {},
   "source": [
    "#### Model inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6e30794",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (672x224 and 4096x1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Pytorch_for_fyp\\envfyp\\AKN32.ipynb Cell 28\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_vgg \u001b[39m=\u001b[39m vgg_model(img_preproc)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m output_akn \u001b[39m=\u001b[39m akn_model(img_preproc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (672x224 and 4096x1000)"
     ]
    }
   ],
   "source": [
    "output_vgg = vgg_model(img_preproc)\n",
    "output_akn = akn_model(img_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0297a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "softmax_vgg = nn.Softmax(dim=1)\n",
    "probabilities_vgg = softmax_vgg(output_vgg)\n",
    "_, predicted_vgg_idx = torch.max(probabilities_vgg, 1)\n",
    "predicted_label_vgg = predicted_vgg_idx.item()\n",
    "print(predicted_label_vgg)\n",
    "\n",
    "softmax_akn = nn.Softmax(dim=1)\n",
    "probabilities_akn = softmax_akn(output_akn)\n",
    "_, predicted_akn_idx = torch.max(probabilities_akn, 1)\n",
    "predicted_label_akn = predicted_akn_idx.item()\n",
    "print(predicted_label_akn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109385d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Pytorch_for_fyp\\envfyp\\AKN32.ipynb Cell 30\u001b[0m in \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m val_dataloader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         output_vgg \u001b[39m=\u001b[39m vgg_model(img_preproc)  \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(output_vgg\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)  \u001b[39m# Get predicted labels\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         total_vgg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\vgg.py:69\u001b[0m, in \u001b[0;36mVGG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m     68\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier(x)\n\u001b[0;32m     70\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct_vgg = 0\n",
    "total_vgg = 0\n",
    "correct_akn = 0\n",
    "total_akn = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_dataloader:\n",
    "        output_vgg = vgg_model(img_preproc)  # Forward pass\n",
    "        _, predicted = torch.max(output_vgg.data, 1)  # Get predicted labels\n",
    "        total_vgg += labels.size(0)\n",
    "        correct_vgg += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_vgg / total_vgg\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_dataloader:\n",
    "        output_akn = akn_model(img_preproc)  # Forward pass\n",
    "        _, predicted = torch.max(output_akn.data, 1)  # Get predicted labels\n",
    "        total_akn += labels.size(0)\n",
    "        correct_akn += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct_akn / total_akn\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3945f4a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Pytorch_for_fyp\\envfyp\\AKN32.ipynb Cell 31\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X43sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(best_model_wts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X43sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X43sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(vgg_model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Pytorch_for_fyp/envfyp/AKN32.ipynb#X43sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                        num_epochs\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss / dataset_sizes\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            # deep copy the model\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(vgg_model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
